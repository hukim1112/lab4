{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abspath = os.path.abspath('.')\n",
    "root_path = os.path.split(abspath)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, osp.join(root_path, 'cocoapi' ,'PythonAPI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "class Dataset(object):\n",
    "    \n",
    "    dataset_name = 'COCO'\n",
    "    num_kps = 17\n",
    "    kps_names = ['nose', 'l_eye', 'r_eye', 'l_ear', 'r_ear', 'l_shoulder',\n",
    "    'r_shoulder', 'l_elbow', 'r_elbow', 'l_wrist', 'r_wrist',\n",
    "    'l_hip', 'r_hip', 'l_knee', 'r_knee', 'l_ankle', 'r_ankle']\n",
    "    kps_symmetry = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (11, 12), (13, 14), (15, 16)]\n",
    "    kps_lines = [(1, 2), (0, 1), (0, 2), (2, 4), (1, 3), (6, 8), (8, 10), (5, 7), (7, 9), (12, 14), (14, 16), (11, 13), (13, 15), (5, 6), (11, 12)]\n",
    "\n",
    "    human_det_path = osp.join(root_path, 'datasets', dataset_name, 'dets', 'human_detection.json') # human detection result\n",
    "    img_path = osp.join(root_path, 'datasets', dataset_name, 'images')\n",
    "    train_annot_path = osp.join(root_path, 'datasets', dataset_name, 'annotations', 'person_keypoints_train2017.json')\n",
    "    val_annot_path = osp.join(root_path, 'datasets', dataset_name, 'annotations', 'person_keypoints_val2017.json')\n",
    "    test_annot_path = osp.join(root_path, 'datasets', dataset_name, 'annotations', 'image_info_test-dev2017.json')\n",
    "\n",
    "    def load_train_data(self, score=False):\n",
    "        coco = COCO(self.train_annot_path)\n",
    "        train_data = []\n",
    "        for aid in coco.anns.keys():\n",
    "            ann = coco.anns[aid]\n",
    "            imgname = 'train2017/' + coco.imgs[ann['image_id']]['file_name']\n",
    "            joints = ann['keypoints']\n",
    " \n",
    "            if (ann['image_id'] not in coco.imgs) or ann['iscrowd'] or (np.sum(joints[2::3]) == 0) or (ann['num_keypoints'] == 0):\n",
    "                continue\n",
    "           \n",
    "            # sanitize bboxes\n",
    "            x, y, w, h = ann['bbox']\n",
    "            img = coco.loadImgs(ann['image_id'])[0]\n",
    "            width, height = img['width'], img['height']\n",
    "            x1 = np.max((0, x))\n",
    "            y1 = np.max((0, y))\n",
    "            x2 = np.min((width - 1, x1 + np.max((0, w - 1))))\n",
    "            y2 = np.min((height - 1, y1 + np.max((0, h - 1))))\n",
    "            if ann['area'] > 0 and x2 >= x1 and y2 >= y1:\n",
    "                bbox = [x1, y1, x2-x1, y2-y1]\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if score:\n",
    "                data = dict(image_id = ann['image_id'], imgpath = imgname, bbox=bbox, joints=joints, score=1)\n",
    "            else:\n",
    "                data = dict(image_id = ann['image_id'], imgpath = imgname, bbox=bbox, joints=joints)\n",
    "\n",
    "            train_data.append(data)\n",
    "\n",
    "        return train_data\n",
    "    \n",
    "    def load_val_data_with_annot(self):\n",
    "        coco = COCO(self.val_annot_path)\n",
    "        val_data = []\n",
    "        for aid in coco.anns.keys():\n",
    "            ann = coco.anns[aid]\n",
    "            if ann['image_id'] not in coco.imgs:\n",
    "                continue\n",
    "            imgname = 'val2017/' + coco.imgs[ann['image_id']]['file_name']\n",
    "            bbox = ann['bbox']\n",
    "            joints = ann['keypoints']\n",
    "            data = dict(image_id = ann['image_id'], imgpath = imgname, bbox=bbox, joints=joints, score=1)\n",
    "            val_data.append(data)\n",
    "\n",
    "        return val_data\n",
    "\n",
    "    def load_annot(self, db_set):\n",
    "        if db_set == 'train':\n",
    "            coco = COCO(self.train_annot_path)\n",
    "        elif db_set == 'val':\n",
    "            coco = COCO(self.val_annot_path)\n",
    "        elif db_set == 'test':\n",
    "            coco = COCO(self.test_annot_path)\n",
    "        else:\n",
    "            print('Unknown db_set')\n",
    "            assert 0\n",
    "\n",
    "        return coco\n",
    "\n",
    "    def load_imgid(self, annot):\n",
    "        return annot.imgs\n",
    "\n",
    "    def imgid_to_imgname(self, annot, imgid, db_set):\n",
    "        imgs = annot.loadImgs(imgid)\n",
    "        imgname = [db_set + '2017/' + i['file_name'] for i in imgs]\n",
    "        return imgname\n",
    "\n",
    "    def evaluation(self, result, gt, result_dir, db_set):\n",
    "        result_path = osp.join(result_dir, 'result.json')\n",
    "        with open(result_path, 'w') as f:\n",
    "            json.dump(result, f)\n",
    "\n",
    "        result = gt.loadRes(result_path)\n",
    "        cocoEval = COCOeval(gt, result, iouType='keypoints')\n",
    "\n",
    "        cocoEval.evaluate()\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize()\n",
    "\n",
    "        result_path = osp.join(result_dir, 'result.pkl')\n",
    "        with open(result_path, 'wb') as f:\n",
    "            pickle.dump(cocoEval, f, 2)\n",
    "            print(\"Saved result file to \" + result_path)\n",
    "    \n",
    "    def vis_keypoints(self, img, kps, kp_thresh=0.4, alpha=1):\n",
    "\n",
    "        # Convert from plt 0-1 RGBA colors to 0-255 BGR colors for opencv.\n",
    "        cmap = plt.get_cmap('rainbow')\n",
    "        colors = [cmap(i) for i in np.linspace(0, 1, len(self.kps_lines) + 2)]\n",
    "        colors = [(c[2] * 255, c[1] * 255, c[0] * 255) for c in colors]\n",
    "\n",
    "        # Perform the drawing on a copy of the image, to allow for blending.\n",
    "        kp_mask = np.copy(img)\n",
    "\n",
    "        # Draw mid shoulder / mid hip first for better visualization.\n",
    "        mid_shoulder = (\n",
    "            kps[:2, 5] +\n",
    "            kps[:2, 6]) / 2.0\n",
    "        sc_mid_shoulder = np.minimum(\n",
    "            kps[2, 5],\n",
    "            kps[2, 6])\n",
    "        mid_hip = (\n",
    "            kps[:2, 11] +\n",
    "            kps[:2, 12]) / 2.0\n",
    "        sc_mid_hip = np.minimum(\n",
    "            kps[2, 11],\n",
    "            kps[2, 12])\n",
    "        nose_idx = 0\n",
    "        if sc_mid_shoulder > kp_thresh and kps[2, nose_idx] > kp_thresh:\n",
    "            cv2.line(\n",
    "                kp_mask, tuple(mid_shoulder.astype(np.int32)), tuple(kps[:2, nose_idx].astype(np.int32)),\n",
    "                color=colors[len(self.kps_lines)], thickness=2, lineType=cv2.LINE_AA)\n",
    "        if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:\n",
    "            cv2.line(\n",
    "                kp_mask, tuple(mid_shoulder.astype(np.int32)), tuple(mid_hip.astype(np.int32)),\n",
    "                color=colors[len(self.kps_lines) + 1], thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Draw the keypoints.\n",
    "        for l in range(len(self.kps_lines)):\n",
    "            i1 = self.kps_lines[l][0]\n",
    "            i2 = self.kps_lines[l][1]\n",
    "            p1 = kps[0, i1].astype(np.int32), kps[1, i1].astype(np.int32)\n",
    "            p2 = kps[0, i2].astype(np.int32), kps[1, i2].astype(np.int32)\n",
    "            if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:\n",
    "                cv2.line(\n",
    "                    kp_mask, p1, p2,\n",
    "                    color=colors[l], thickness=2, lineType=cv2.LINE_AA)\n",
    "            if kps[2, i1] > kp_thresh:\n",
    "                cv2.circle(\n",
    "                    kp_mask, p1,\n",
    "                    radius=3, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)\n",
    "            if kps[2, i2] > kp_thresh:\n",
    "                cv2.circle(\n",
    "                    kp_mask, p2,\n",
    "                    radius=3, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Blend the keypoints.\n",
    "        return cv2.addWeighted(img, 1.0 - alpha, kp_mask, alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcfg = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.27s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_data = dbcfg.load_val_data_with_annot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 292456, 'imgpath': 'val2017/000000292456.jpg', 'bbox': [129.91, 31.93, 60.35, 238.33], 'joints': [167, 60, 2, 169, 54, 2, 163, 54, 2, 0, 0, 0, 151, 54, 2, 160, 93, 2, 145, 94, 2, 0, 0, 0, 153, 116, 2, 0, 0, 0, 176, 138, 2, 157, 149, 2, 147, 151, 2, 153, 194, 1, 151, 206, 2, 143, 235, 2, 155, 257, 2], 'score': 1}\n"
     ]
    }
   ],
   "source": [
    "print(val_data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "img = plt.imread(\n",
    "os.path.join(root_path, 'datasets', 'COCO', 'images', val_data[15]['imgpath']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = val_data[15]['joints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180, 233, 2, 184, 228, 2, 174, 228, 2, 0, 0, 0, 164, 224, 2, 187, 239, 2, 151, 240, 2, 191, 268, 2, 147, 289, 2, 202, 281, 2, 180, 268, 2, 166, 298, 2, 142, 299, 2, 178, 348, 1, 149, 349, 2, 185, 402, 1, 156, 403, 2]\n"
     ]
    }
   ],
   "source": [
    "print(kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_array = np.array(kps).reshape((17, 3))\n",
    "print(kps_array.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dbcfg.vis_keypoints(img, kps_array.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [i['imgpath'] for i in val_data]\n",
    "bbox = [i['bbox'] for i in val_data]\n",
    "joints = [i['joints'] for i in val_data]\n",
    "scores = [i['score'] for i in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((image_paths, bbox, joints, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sample in ds.take(1):\n",
    "    for i in sample:\n",
    "        data.append(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_process\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, osp.join(root_path, 'config'))\n",
    "import config\n",
    "config = config.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(dbcfg.img_path + os.sep + 'val2017/000000425226.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_process.image_process(img, data[1], data[2], config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add configuration filepath into python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, osp.join(root_path, 'config'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(bbox, config):\n",
    "    input_shape = tf.constant(config.input_shape)\n",
    "    aspect_ratio = input_shape[1]/input_shape[0]\n",
    "    x, y, w, h = bbox\n",
    "    center = np.array([x + w * 0.5, y + h * 0.5])\n",
    "    if w > aspect_ratio * h:\n",
    "        h = w / aspect_ratio\n",
    "    elif w < aspect_ratio * h:\n",
    "        w = h * aspect_ratio\n",
    "    scale = np.array([w,h]) * 1.25\n",
    "    rotation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rotate_tf(image):\n",
    "    if image.shape.__len__() ==4:\n",
    "            \n",
    "        random_angles = tf.random.uniform(shape = (tf.shape(image)[0], ), minval = -np\n",
    "        .pi / 4, maxval = np.pi / 4)\n",
    "    if image.shape.__len__() ==3:\n",
    "        random_angles = tf.random.uniform(shape = (), minval = -np\n",
    "        .pi / 4, maxval = np.pi / 4)\n",
    "\n",
    "    return tfa.image.rotate(image,random_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  [image,] = tf.py_function(random_rotate_image, [image], [tf.float32])\n",
    "\n",
    "  img = tf.image.resize(img, [config.img_shape[1], config.img_shape[0]])\n",
    "  return rotate_tf(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  # load the raw data from the file as a string\n",
    "  file_path = dbcfg.img_path + os.sep + file_path\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path, bbox, joints, score):\n",
    "    img = process_path(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_ds = ds.map(process_data).batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ds.take(1):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
